{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test.csv', header=None)\n",
        "train = pd.read_csv('train.csv', encoding='big5')\n",
        "output = pd.read_csv('sampleSubmission.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "data = train.iloc[0:, 3:]\n",
        "data = data.fillna(0).replace('NR', 0)\n",
        "data = np.asarray(data)\n",
        "switch_time = np.empty(shape=(18, 12 * 20 * 24))\n",
        "for day in range(12 * 20):\n",
        "    for hour in range(24):\n",
        "        switch_time[:, day * 24 + hour] = data[18 * (day): 18 * (day + 1), hour]\n",
        "# row for detect result, colume for each hourï¼ˆat interval of 24 hour, 20 day and 12 month)\n",
        "\n",
        "# ues every 9 hour data as one x to predict the 10th's pm value\n",
        "# the shape for X should be 5652, 18*9 (include PM value of previous 9 hour)\n",
        "# shape for y should be 5652, 1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_feature = 18\n",
        "X_train = np.empty(shape=(switch_time.shape[1] - 9 * 12, num_feature * 9), dtype=float)\n",
        "y_train = np.empty(shape=(switch_time.shape[1] - 9 * 12, 1))\n",
        "\n",
        "for month in range(12):\n",
        "    for day in range(20):\n",
        "        for hour in range(24):\n",
        "            if day == 19 and hour > 14:\n",
        "                continue\n",
        "            X_train[month * 471 + day * 24 + hour, :] = switch_time[:, month * 480 + day * 24 + hour:month * 480 + day * 24 + hour + 9].reshape((1, -1))\n",
        "            y_train[month * 471 + day * 24 + hour, 0] = switch_time[9, month * 480 + day * 24 + hour + 9]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization\n",
        "\n",
        "\n",
        "def normalization(X_train):\n",
        "    x_mean = X_train.mean(axis=0)\n",
        "    x_std = X_train.std(axis=0)\n",
        "    for i in range(X_train.shape[0]):\n",
        "        for j in range(X_train.shape[1]):\n",
        "            if not x_std[j] == 0:\n",
        "                X_train[i][j] = (X_train[i][j] - x_mean[j]) / x_std[j]\n",
        "            else:\n",
        "                print(i, j)\n",
        "    return X_train\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = normalization(X_train)\n",
        "# performance is better without normalization, might due to customized gradient\n",
        "\n",
        "# 4 types of gradient methods\n",
        "def adagrad(X_train, iteration=10000, rate=10):\n",
        "    dim = X_train.shape[1] + 1\n",
        "    w = np.zeros((dim, 1))\n",
        "    # add bias\n",
        "    X = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1).astype(float)\n",
        "    learning_rate = np.array(np.ones((dim, 1)) * rate)\n",
        "    adagrad_sum = np.zeros((dim, 1))\n",
        "    loss_histroy = []\n",
        "    for i in range(iteration):\n",
        "        loss = y_train - X.dot(w)\n",
        "        avg_loss = np.power(np.sum(np.power(loss, 2)) / X.shape[0], 0.5)\n",
        "        grad = (-2) * X.transpose().dot(loss)\n",
        "        adagrad_sum += grad ** 2\n",
        "        w = w - (learning_rate * grad) / (np.sqrt(adagrad_sum) + 0.005)\n",
        "        if i % (iteration / 20) == 0:\n",
        "            print(avg_loss)\n",
        "            loss_histroy.append(avg_loss)\n",
        "    return w, loss_histroy"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def l2_adagrad(X_train, iteration=50000, rate=1000, Lambda=0.000001):\n",
        "    dim = X_train.shape[1] + 1\n",
        "    w = np.zeros((dim, 1))\n",
        "    # add bias\n",
        "    X = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1).astype(float)\n",
        "    learning_rate = np.array(np.ones((dim, 1)) * rate)\n",
        "    adagrad_sum = np.zeros((dim, 1))\n",
        "    loss_histroy = []\n",
        "    for i in range(iteration):\n",
        "        loss = np.power(y_train - X.dot(w), 2)\n",
        "        l2 = np.power(w, 2) * Lambda\n",
        "        avg_loss = np.power((np.sum(loss) + np.sum(l2)) / X.shape[0], 0.5)\n",
        "        grad = (-2) * X.transpose().dot(loss)\n",
        "        adagrad_sum += grad ** 2\n",
        "        w = w * (1 - (Lambda * learning_rate)) - (learning_rate * grad) / (np.sqrt(adagrad_sum) + 0.005)\n",
        "        if i % (iteration / 20) == 0:\n",
        "            print(avg_loss)\n",
        "            loss_histroy.append(avg_loss)\n",
        "    return w, loss_histroy\n",
        "\n",
        "\n",
        "def RMSprop(X_train, iteration=1000, rate=0.2, decay_rate=0.99):\n",
        "    dim = X_train.shape[1] + 1\n",
        "    w = np.zeros((dim, 1))\n",
        "    r = np.zeros((dim, 1))\n",
        "    # add bias\n",
        "    X = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1).astype(float)\n",
        "    learning_rate = np.array(np.ones((dim, 1)) * rate)\n",
        "    loss_histroy = []\n",
        "    for i in range(iteration):\n",
        "        loss = y_train - X.dot(w)\n",
        "        avg_loss = np.power(np.sum(np.power(loss, 2)) / X.shape[0], 0.5)\n",
        "        grad = (-2) * X.transpose().dot(loss)\n",
        "        r = r * decay_rate + ((1 - decay_rate) * np.multiply(grad, grad))\n",
        "        w = w - ((learning_rate / (np.sqrt(r) + 0.0000001)) * grad)\n",
        "        if i % (iteration / 20) == 0:\n",
        "            print(avg_loss)\n",
        "            loss_histroy.append(avg_loss)\n",
        "    return w, loss_histroy\n",
        "\n",
        "\n",
        "def Adam(X_train, iteration=1000, rate=0.2, decay_rate_s=0.9, decay_rate_r=0.999):\n",
        "    dim = X_train.shape[1] + 1\n",
        "    w = np.zeros((dim, 1))\n",
        "    s = np.zeros((dim, 1))\n",
        "    r = np.zeros((dim, 1))\n",
        "    # add bias\n",
        "    X = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1).astype(float)\n",
        "    learning_rate = np.array(np.ones((dim, 1)) * rate)\n",
        "    loss_histroy = []\n",
        "    for i in range(iteration):\n",
        "        loss = y_train - X.dot(w)\n",
        "        avg_loss = np.power(np.sum(np.power(loss, 2)) / X.shape[0], 0.5)\n",
        "        grad = (-2) * X.transpose().dot(loss)\n",
        "        s = s * decay_rate_s + ((1 - decay_rate_s) * grad)\n",
        "        r = r * decay_rate_r + ((1 - decay_rate_r) * np.multiply(grad, grad))\n",
        "        delta_s = s / (1 - decay_rate_s)\n",
        "        delta_r = r / (1 - decay_rate_r)\n",
        "        w = w - ((learning_rate * delta_s) / (np.sqrt(delta_r) + 0.000000001))\n",
        "        if i % (iteration / 20) == 0:\n",
        "            print(avg_loss)\n",
        "            loss_histroy.append(avg_loss)\n",
        "    return w, loss_histroy\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def predict(test, w, loss_histroy):\n",
        "    x_test_before = test.iloc[:, 2:]\n",
        "    x_test_before = x_test_before.fillna(0).replace('NR', 0)\n",
        "    x_test_before = np.array(x_test_before)\n",
        "    x_test = np.empty((240, num_feature * 9))\n",
        "    for id in range(240):\n",
        "        x_test[id, :] = x_test_before[id * num_feature:(id + 1) * num_feature, :].reshape(1, -1)\n",
        "    # normalization\n",
        "    xt_nor = x_test\n",
        "    # xt_nor = normalization(x_test)\n",
        "\n",
        "    test_x = np.concatenate((np.ones((xt_nor.shape[0], 1)), xt_nor), axis=1).astype(float)\n",
        "    ans = test_x.dot(w)\n",
        "    id_ls = []\n",
        "    for id in range(240):\n",
        "        id_ls.append('id_' + str(id))\n",
        "    ans_ar = np.concatenate((np.asarray(id_ls).reshape(240, 1), ans), axis=1)\n",
        "    ans_df = pd.DataFrame(ans_ar, columns=['id', 'value'])\n",
        "    ans_df.to_csv('answer.csv', index=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training and predict\n",
        "w_adam, loss_histroy_adam = Adam(X_train, iteration=10000, rate=0.05)\n",
        "predict(test, w_adam, loss_histroy_adam)\n",
        "w_rms, loss_histroy_rms = RMSprop(X_train, iteration=10000, rate=0.01, decay_rate=0.9)\n",
        "predict(test, w_rms, loss_histroy_rms)\n",
        "\n",
        "w_l2, loss_histroy_l2 = l2_adagrad(X_train, iteration=10000, Lambda=0.001)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualazation\n",
        "plt.plot(list(np.arange(0, len(loss_histroy_adam))), loss_histroy_adam)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn practicing\n",
        "# data processing\n",
        "X_train\n",
        "x_test_before = test.iloc[:, 2:]\n",
        "x_test_before = x_test_before.fillna(0).replace('NR', 0)\n",
        "x_test_before = np.array(x_test_before)\n",
        "x_test = np.empty((240, num_feature * 9))\n",
        "for id in range(240):\n",
        "    x_test[id, :] = x_test_before[id * num_feature:(id + 1) * num_feature, :].reshape(1, -1)\n",
        "# normalization\n",
        "x_test\n",
        "X_train_nor = normalization(X_train)\n",
        "xt_nor = normalization(x_test)\n",
        "test_x = np.concatenate((np.ones((xt_nor.shape[0], 1)), xt_nor), axis=1).astype(float)\n",
        "y_train = y_train.reshape(y_train.shape[0],)\n",
        "svr_param = [{'kernel': ['linear'], 'C':[0.5, 1, 1.5]}]\n",
        "svr = GridSearchCV(SVR(cache_size=400), svr_param, cv=2, verbose=1.5, scoring='neg_mean_squared_error')\n",
        "svr.fit(X_train_nor, y_train)\n",
        "svr.best_score_\n",
        "svr.best_params_\n",
        "svr.cv_results_['params']\n",
        "svr.cv_results_['mean_test_score']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Users/ryan/anaconda3/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}